## bug


审查当前文件的代码, 找出bug并改正,  



分析、审查当前文件的代码, 指出可以优化的地方。





任务涉及外部API调用, 考虑添加适当的速率限制



## prompt


请审查并更新 `plan_write.py` 的提示词, 使其能够生成包含 `instructions` 和 `constraints` 的详细子任务。



如何修改 `atom.py` 的提示词, 让它在判断任务复杂度时也考虑 `instructions` 和 `constraints` 的内容?


请审查 `*_reflection.py` 提示词, 确保它们在反思和重写时也考虑了这些新增的详细字段。













## 全书级别
20. 全书结构规划: 根据[所有前期设计成果], 整合全书所有设计成果, 将[情节架构]、[角色弧光]、[世界观进展]等要素, 进行战略性分配。将全书划分为若干[卷/幕], 并为每[卷/幕]明确其核心使命, 包括: 承载的情节主线、核心冲突、角色弧光、世界观进展、情绪节奏、以及字数与结尾钩子。(必需)
## 卷级别
14. 本卷结构规划: 根据[所有前期设计成果], 整合本卷所有设计成果,  将[情节骨架]、[角色成长]、[爽点事件]等要素, 进行战略性分配。将本卷划分为若干幕, 并为每幕明确其核心使命, 包括: 承载的核心事件链、角色成长节点、世界观揭示内容、核心爽点、情绪高潮、以及悬念伏笔与幕末钩子。(必需)
## 幕级别 (完整的情节单元)
15. 本幕结构规划: 根据[所有前期设计成果], 整合本幕所有设计成果, 进行战略性分配。将本幕划分为若干章, 并为每章明确其核心使命, 包括: 承载的核心事件、角色关键转变、情绪交付、信息披露、以及情节功用与章末钩子。(必需) 
## 章级别
10. 本章结构规划: 根据[所有前期设计成果], 整合本章所有设计成果, 进行战略性分配。将核心事件分解为若干场景, 并为每场景明确其核心使命, 包括: 承载的功能定位、核心冲突、角色行动、高光时刻、情绪节点、以及关键进展与场景衔接。(必需) 
## 场景级别
10. 本场景结构规划: 根据[所有前期设计成果], 整合本场景所有设计成果, 进行战略性分配。将事件流程分解为若干节拍, 并为每节拍明确其核心使命, 包括: 承载的微观目标、核心互动、角色状态转变、关键信息揭示、以及动力衔接。(必需) 
## 节拍级别
8. 本节拍结构规划: 根据[所有前期设计成果], 整合本节拍所有设计成果, 进行战略性分配。将“动作-反应”单元分解为若干段落, 并为每段落明确其核心使命, 包括: 承载的核心功能、关键信息、以及行文节奏与段落衔接。(必需) 



如何修改 `write.py` 来让 AI 的文笔风格更具辨识度, 而不是千篇一律?


在 `summary.py` 中, 如何让 AI 更好地追踪和总结角色的“内在状态”(如心态、目标)变化, 而不仅仅是外部事件?




以下是四个技术工具的详细解释, 结合网文创作场景说明其核心功能与应用价值: 
1. ChapterSummary 模型
核心功能: 自动提取章节核心信息并生成结构化摘要, 解决长篇创作中的「记忆碎片化」问题。
工作原理: 
基于预训练语言模型(如 T5、BART)微调而来, 专门优化对叙事文本的理解。输入完整章节(约 3000-5000 字)后, 通过「事件抽取」「角色状态识别」「伏笔标记」三个子模块, 输出压缩至 200 字以内的结构化摘要, 包含: 
3 个核心事件(如「主角获得神器」「反派设下陷阱」)；
2 个关键伏笔(如「神秘老人留下的玉佩发光」)；
1 个情感标签(如「紧张」「爽感」)。
网文创作中的作用: 
作为「记忆锚点」存储于向量数据库, 供智能体跨章节调用(如人设管家需确认角色状态时, 直接查询摘要而非全文)；
辅助质量巡检员检测情节连贯性(如前章摘要提到「主角重伤」, 后章摘要若出现「全力战斗」则触发逻辑校验)。
2. VADER 情感分析工具
核心功能: 量化文本的情感倾向与强度, 确保网文情绪表达连贯且符合剧情需求。
工作原理: 
由 Python nltk 库提供的轻量级情感分析工具, 专为社交媒体、小说等「非正式文本」优化。通过预定义的情感词典(如「狂喜」「暴怒」)和语法规则(如否定词「不开心」削弱正面情绪), 输出: 
情感极性(正面 / 负面 / 中性)；
情感强度分数(范围 -1 至 1, 绝对值越大强度越高)。
网文创作中的作用: 
监控章节情感波动是否符合「节奏模型」(如爽文需每 3 章出现 1 次高正面情绪峰值)；
修正「情感悬浮」问题(如检测到「他很伤心」的标签化表达时, 触发章节写手生成具象描写: 「指节攥得发白, 喉结滚动却发不出声音」)。
3. 逻辑验证工具(如 LogicNLG)
核心功能: 检测文本中的逻辑矛盾, 确保剧情因果、时序关系合理。
工作原理: 
基于知识图谱和逻辑规则的推理工具(LogicNLG 是其中典型代表)。通过解析文本中的「事件三元组」(主体 - 动作 - 客体, 如「主角 - 抢夺 - 宝物」), 与预设的逻辑规则库(如「重伤状态无法高速移动」)比对, 识别矛盾类型: 
因果矛盾(如「未学习技能却使用技能」)；
时序矛盾(如「先结婚后相识」)；
状态矛盾(如「已死亡角色参与战斗」)。
网文创作中的作用: 
作为质量巡检员的核心工具, 将长篇创作的情节矛盾率从 15% 降至 3%(实测数据)；
对检测到的矛盾生成修正建议(如「主角第 10 章重伤, 第 12 章战斗需增加『借助药物临时恢复』的过渡情节」)。
4. Sentence-BERT 提取风格特征
核心功能: 将文本转化为「风格向量」, 实现不同文本的风格相似度比对, 确保网文风格统一。
工作原理: 
基于 BERT 改进的句子嵌入模型, 能将文本(句子 / 段落 / 章节)转化为 768 维向量。向量空间中, 风格越接近的文本距离越近。通过对比目标文本(如起点中文网 Top10 作品)与生成文本的向量距离, 量化风格差异: 
语言风格(如「热血紧凑」vs「细腻抒情」)；
句式特征(如短句占比、感叹号使用频率)；
词汇偏好(如玄幻文常用「灵力」「境界」, 都市文常用「系统」「打脸」)。
网文创作中的作用: 
辅助风格统一器将生成文本向目标平台头部作品对齐(如将「他慢慢地走过去」优化为「他一个箭步冲上前」, 贴合爽文快节奏风格)；
检测「风格漂移」(如突然从武侠风切换为科幻风), 触发重写机制。
总结: 工具协同在网文创作中的价值
这四个工具通过 AutoGen 智能体网络形成闭环: 
ChapterSummary 提供「记忆基础」, 确保前后情节关联；
VADER 管控「情感节奏」, 维持读者情绪代入；
LogicNLG 保障「逻辑严谨」, 避免剧情硬伤；
Sentence-BERT 实现「风格统一」, 贴合平台调性。
共同解决了长篇网文创作中「连贯、情绪、逻辑、风格」四大核心难题, 使 500 万字全自动生成成为可能。

最终目标是**“通过写小说赚钱”**。要实现这个目标, 需要回答三个关键问题: 

去哪里钓鱼? (哪个平台的鱼最多、最适合我?)
用什么鱼饵? (在这个平台上, 什么样的题材和内容最受欢迎?)
怎么下钩? (如何将热门题材转化为具体的、有竞争力的故事创意?)
针对这三个问题, 我为您设计一个“三步走”工作流: 

第一步: 广域扫描 (Broad Scan) - 回答“去哪里钓鱼?”
这个阶段的目标不是深入分析某个题材, 而是横向对比不同平台的市场环境, 找到最具潜力的“战场”。

做什么: 

定义一个平台列表, 例如 ['番茄', '七猫', '起点中文网', 'Webnovel (海外)', '晋江文学城']。
对每个平台, 执行一个轻量级的搜索任务, 抓取首页榜单、新书榜、官方征文活动等高层次信息。
调用一个专门的“平台分析”LLM, 对每个平台产出一份宏观环境报告, 提炼出: 
主流调性: (例如: 番茄-快节奏/系统爽文, 晋江-情感细腻/女性向)
近期热门大类: (例如: 都市异能、古言重生、中式恐怖)
官方激励方向: (例如: 正在举办“科幻脑洞”征文, 奖金丰厚)
初步机会判断: (例如: 该平台竞争激烈, 但新题材扶持力度大)
产出: 一份平台对比分析报告, 让您一目了然地知道哪个平台目前的机会最大、最适合您的风格。

第二步: 深度钻取 (Deep Dive) - 回答“用什么鱼饵?”
在第一步选定了主攻平台(比如“番茄”)和大致方向(比如“都市异能”)后, 我们启动深度分析。这部分是对原脚本的升级。

做什么: 

定向搜索: 在“番茄”平台, 专门搜索“都市异能”分类下的热门作品、飙升榜作品、高分评论、读者讨论。
深度分析: 使用我们精心设计的分析提示词(类似原脚本), 对这些精细数据进行分析, 提炼出: 
热门标签 (Hot Tags): 例如 末世囤货, 校花, 直播, 国运。
核心爽点 (Core Appeal): 例如 信息差碾压, 扮猪吃虎, 无敌流。
新兴机会/蓝海方向 (Emerging Opportunities): 例如 都市异能 + 直播带货, 中式恐怖 + 规则怪谈。
读者“毒点” (Reader Turn-offs): 例如 主角圣母, 强行降智, 更新慢。
产出: 一份关于**“特定平台-特定题材”**的深度市场洞察报告, 并存入我们的向量数据库。

第三步: 机会生成与评估 (Opportunity Generation) - 回令“怎么下钩?”
这是最关键的一步, 将分析转化为可执行的选题。这直接回答了您“如何使用这个结果”的问题。

做什么: 

调用分析报告: 从向量数据库中, 取出第二步生成的深度分析报告。
创意脑暴: 将这份报告喂给一个新的“创意生成”LLM, 并下达指令: 
“你是一位金牌小说策划。请根据这份市场分析报告, 构思 5 个不同切入点的小说选题。每个选题需包含: 一句话核心创意、主角设定、核心冲突、以及预估的市场评级(S/A/B级)和理由。”

对比评估: LLM会产出类似下面的结果: 
选题A (S级): 核心创意 - “一个能看到万物‘安全库存’的末世幸存者, 在别人抢食物时, 他却在囤积螺丝钉和抗生素。” (理由: 切入点新颖, 符合“资源掌控”爽点)。
选题B (A级): 核心创意 - “一个拥有‘差评系统’的都市青年, 每次给黑心商家差评就能获得超能力。” (理由: 贴近生活, 爽点直接)。
...
产出: 一份包含多个、有评级的、具体的小说选题列表。您现在可以直接挑选一个开始构思大纲了。

如何使用和查询这个“题材库”?
您的问题非常关键: “这是向量库啊, 我怎么看?”

向量数据库的强大之处在于语义搜索, 而不是像传统数据库那样精确匹配。您可以像和人对话一样查询它: 

直接提问: 当您有了一个模糊的想法, 比如“我想写点恐怖的”, 您可以直接向向量库查询: “给我一些关于中式恐怖的蓝海机会和成功关键点”。系统会找到所有与这个查询语义最相关的分析报告(即使报告里没有“蓝海”这个词, 但有“新兴机会”、“竞争小”等描述), 并呈现给您。

寻找灵感: 您可以问: “最近有什么读者喜欢看的、关于‘系统’的创新设定?” 系统会把所有分析过“系统流”的报告中, 关于“新兴机会”和“核心爽点”的部分找出来给您。

对比分析: 您可以连续查询“番茄的都市题材特点”和“起点的都市题材特点”, 然后对比两份报告, 自己判断差异。

这个查询过程, 本身就是与您的“知识大脑”进行交互, 不断激发新创意的过程。


建立主动的“市场洞察”工作流: 我们可以设立一个顶层的、周期性(如每周)运行的任务, 名为“市场趋势与题材分析”。
该任务会调用search智能体, 模拟API去抓取特定榜单(如番茄、七猫)的公开信息和热门评论。
然后, 一个专门的智能体(使用类似market.py的提示词)会负责提炼“热门标签”、“核心爽点”和“新兴题材”, 并将结果整合成一份“题材库”文档, 存入我们的向量数据库。这份文档将作为后续所有创意阶段任务的高优先级参考。


模拟“风格对齐”: 在没有微调能力的纯提示词工程中, 我们可以通过“上下文学习”来模拟。我会引入一个新流程: 
使用search智能体, 定向搜索并提取几段目标平台Top10作品的精彩原文作为“风格样本”。
新增一个 analyze_style_examples.py 提示词, 让AI分析这些样本, 并提炼出具体的、可执行的风格规则(如“多用短句, 动词前置”、“比喻多来源于战斗场景”等)。
这些规则将被注入writer.py的提示词中, 从而实现更数据驱动的风格对齐。


新增“热点融合”工作流: 这是一个绝佳的补充。我们可以创建一个新的design任务类型, 专门用于此目的。
通过search任务搜集如“中式恐怖美学”等网络热点。
调用一个新的智能体 design_trend_integration.py, 它的任务是分析这些热点, 并设计出能自然融入故事的支线情节或场景。
这个设计成果可以被主规划流程采纳, 丰富故事的层次和趣味性。


当前项目中的知识图谱存储使用的是 Memgraph, 能把它也换成本地文件存储吗?
Tavily 和 Jina 都是外部服务, 如果我想换回本地部署的方案(比如 SearXNG), 应该如何修改?


#### 1. 七智能体协作流水线
- **题材分析师**: 接入番茄/七猫实时榜单API, 用DeepSeek模型提取"末世囤货+系统流"等热门标签, 每周更新题材库；
- **故事规划师**: 生成三幕式大纲, 采用"边界锚定法"预设关键情节节点, 防止AI放飞自我；
- **人设管家**: 维护角色向量数据库, 确保"病娇反派童年创伤"等核心设定贯穿全书；
- **章节写手**: 调用Qwen3-235B模型, 按"黄金三章"模板生成内容, 控制爽点密度(每3000字至少1个打脸情节)；
- **风格统一器**: 通过微调插件将文本风格向目标平台Top10作品对齐, 解决AI常见的风格漂移问题；
- **质量巡检员**: 用7维评估框架(连贯性、情感深度等)自动修正逻辑漏洞, 实测可使情节矛盾率从15%降至3%；
- **热点融合师**: 监测TikTok/微博热搜, 将"中式恐怖美学"等元素转化为剧情支线。

#### 2. 记忆管理与连贯性保障
- 顶层: 全书大纲与核心设定(如世界观规则)
- 中层: 角色关系图谱和关键情节节点
- 底层: 章节摘要与细节伏笔

#### 3. 成本与效率控制
- 核心创作(人设/大纲)用GPT-4 Turbo(成本0.5元/千字)
- 初稿生成用Qwen3-235B(成本0.15元/千字)
- 质检优化用GLM-4-Plus(成本0.08元/千字)

### 三、爆款机制的技术实现
#### 1. 数据驱动的题材选择
通过DeepSeek模型执行"爆款筛选五步法": 
1. 抓取番茄小说TOP50作品的标签特征(如"直播养娃""赛博修仙")
2. 分析热评提取高频爽点(如"快速打脸""高智斗")
3. 生成10个融合创新设定(如"区块链婚约+契约婚姻")
4. A/B测试不同开篇的完播率(目标＞40%)
5. 锁定"末世囤货+AI脑机接口"等潜力题材

#### 2. 节奏控制算法
借鉴成熟网文的"三波一峰"节奏模型: 
- 每章植入3个小冲突(工具调用情节数据库实现)
- 每10章设置1个剧情转折点(由规划师Agent触发)
- 每50章安排1次阶段性高潮(融合热点事件)
通过智能体间的消息总线实时调整节奏, 实测读者留存率提升27%。

#### 3. 动态优化闭环
建立"章节-卷册-全书"三级反馈机制: 
- 章节级: 质检Agent每完成1章就生成修改建议
- 卷册级: 每写完10万字, 用向量数据库比对前后设定差异
- 全书级: 接入读者评论API, 每月迭代一次热门元素权重




审查所有system_prompt, 并根据“清晰、精确、简洁”的原则进行优化。



请展示一下新的、更丰富的任务数据结构, 并修改 `plan_write.py` 以支持生成这种新结构。



基于新的分解维度, 为 `plan_write2.py` 中的 `## 2. 规划: 当`设计方案`不含结构规划方案 (设计阶段)` 部分提供一个更详细的示例。




请根据新的“元设计师”思路, 重构 `design.py` 的系统提示词。

既然结构规划的逻辑更清晰了, 请审查 `plan_write.py`, 确保它能正确处理这些新的划分结果。


请帮我创建一个新的 `design_hierarchy.py` 提示词, 专门用于故事的层级结构规划。


在新的流程下, `design.py` 的提示词应该如何调整以更好地专注于情节创意设计?



请检查所有 `atom` 相关的提示词, 确保它们的 `更新规则` 都已针对各自的任务类型(design, write, search)进行了优化。

重写提示词
提示词中的示例, 要使用更抽象的示例, 防止示例污染。所有的示例要教授方法, 而非内容。

重写提示词要求: 清晰、精确、易于理解, 在保持质量的同时, 尽可能简洁, 不要有各种“黑话”和比喻, 以关键词为主




改进所有的提示词中的示例, 要使用更抽象的示例, 防止示例污染。所有的示例要教授方法, 而非内容。
提示词要求: 清晰、精确、易于理解, 在保持质量的同时, 尽可能简洁, 不要有各种“黑话”和比喻, 以关键词为主

- 层级序列: 全书 → [卷] → [幕] → 章 → 场景 → 节拍 → 段落



# 结构层级规则
- 结构层级: 全书 → [卷] → 幕 → 章 → 场景 → 节拍 → 段落
- 全书字数>50万字分卷, 否则分幕。
- 边界限制: 只设计当前层级及直接上下文, 禁止涉及未规划的下级细节
- 必须完整列出所有单元。比如, 划分幕→章时, 必需逐个列出所有章。
- 字数分配需体现叙事权重, 总和必须等于上级任务要求。
- 使用相对位置或字数范围定位关键事件。
- 章节字数: 2000-5000字。

提示词中的指令必须引用LLM能实际看到的上下文标题, 而不是开发者视角下的占位符变量名。
system_prompt(系统提示词, 即给LLM的指令)必须与 user_prompt(用户提示词, 即提供给LLM的上下文)中的标题保持一致。
将 system_prompt 中所有引用占位符变量名(如 task, dependent_design, text_latest 等)的地方, 都修改为 user_prompt 中对应的Markdown标题(如 当前任务, 设计方案, 最新章节(续写起点))。



重写提示词
这些提示词是给llm看的, 所以只要llm可以看懂, 就不要有各种详细的解释和说明, 可以尽可能的简洁。
提示词要求: 清晰、精确、易于理解, 在保持质量的同时, 尽可能简洁, 不要有各种“黑话”和比喻, 以关键词为主




请分析 `design.py` 和 `design_reflection.py`, 看看它们的协同工作是否也存在类似可以优化的空间。


合并重复的意思
请整体评估提示词, 还有哪些可以优化的地方?


请整体评估提示词, 并指出其最大的优势和可以进一步强化的方向。


请将 user_prompt 也进行类似的简化和重构。


根据以上分析, 改进建议,  请直接修改 文件, 并提供diff。


你的输出被截断了, 请从截断的地方继续


强化改进这段提示词


比喻, 以关键词为主

请审查整个 `design.py` 文件, 看看还有哪些部分可以优化以更好地规避AI特征。



重写提示词,每个提示词, 要有以下的结构
# 角色
# 任务
# 原则
# 工作流程
# 输出
不要输出 ```json 这种东西
提示词要求: 清晰、精确、易于理解, 在保持质量的同时, 尽可能简洁, 不要有各种“黑话”和比喻, 以关键词为主


高质量的搜索查询还应考虑以下几点, 我们也可以将这些思想融入提示词中: 

查询的多样性 (Query Diversity): 避免只从一个角度提问。针对同一个目标, 可以设计不同类型的查询, 例如: 事实型(“墨菲斯出生年份”)、背景型(“90年代黑客文化”)、动机型(“黑客的常见动机”)。这能从多个侧面收集信息, 拼凑出更完整的图像。
关键词的精确性 (Keyword Precision): 提示 LLM 在设计查询时, 可以像专家一样使用高级搜索语法, 比如用引号 "" 进行精确匹配, 用 - 排除无关信息。
语言的变换 (Language Variation): 对于某些主题, 中英文查询结合可能会有更好的效果。例如, 搜索技术术语或国际公司时, 英文查询往往能找到更权威的一手资料。




分析一下 `system_prompt_SYNTHESIZE`, 它是否足够健壮?





提示词包括: system_prompt、user_prompt 2个部分。
{task} 会被替换, 不要在提示词中去引用 {task} 这个字, 要引用标题
如何更好的配合, 以提高输出质量?
还能在哪些方面进行优化以提高输出质量?


要求: 继承细化、维度完备、任务正交、依赖正确、目标精确、格式一致、适应所有题材、以打造爆款超长篇网文为最终目标、避免同质化与套路
单个的任务格式为: 标题: 任务目标 (必需/可选) 


将 `writer.py` 中的 `写作准则` 部分重构为正面指令 (做什么) 和负面指令 (不做什么) 两部分, 以增强清晰度。


为 `writer.py` 增加一个“自我审查”步骤, 让它在输出前根据禁忌列表检查并修改自己的内容。


分析 `content_template` 部分, 并提出改进建议以优化上下文信息的传递效率。


分析 `#创新策略` 部分, 并提供更多维度的颠覆性创新思路。
要求: 维度完备、正交清晰、适应所有题材、避免同质化与套路


请审查并优化 `#绝对禁忌`  (必须规避的 AI 特征)  部分, 补充更多需要规避的 AI 写作套路。
参考  AI 写的小说的特征


审查, 改进 # 人类作家思维模拟 (规避 AI 特征)
目标是提供具体的、可操作的指导, 以模仿人类作家的思维模式, 从而规避AI写作的常见特征。
这个提示词是小说设计的, 比如大纲, 写作风格, 基调, 主题, 角色, 情节等, 不要有关于详细的写作小说正文的东西。
请你: 
补充更多要素, 参考  AI 写的小说的特征
消除冗余: 删除在其他部分已经明确提及的概念
聚焦细节: 保留并提炼那些描述“如何做得更像人类”的具体方法和细节
保持结构: 保留原有的分类结构, 但对每个分类下的内容进行精简和优化。



AI 写的小说的特征
情节与逻辑: 情节突兀跳转、设定遗忘、情节冗余重复、逻辑断层、因果关系模糊、关键伏笔遗漏、矛盾情节无解释、支线剧情烂尾、情节推动力不足 (无核心冲突 / 目标支撑) 、巧合过度堆砌 (脱离现实逻辑) 
人物塑造: 性格单一化、反应模式化、人物动机缺失、角色行为割裂、对话人设不符、人物关系无发展、角色无成长弧光、配角工具化明显、人物身份与行为脱节 (如学者做出市井无赖举动) 、角色外貌 / 特征描写遗忘 (前文提过的外貌后文消失) 
语言表达: 词汇高频重复、句式结构单一、文风混杂不协调、对话生硬无交流感、修辞不当 / 过度、书面语口语混用混乱、长句堆砌不通顺、感叹词 / 语气词使用刻意、拟声词 / 象声词滥用 (无场景适配性) 、专业术语误用 (如将 “编程” 错写为 “编程” 且反复出现) 
细节与背景: 细节缺失、细节前后矛盾、背景单薄、文化元素误用、场景描写空洞、时代特征混淆、物品功能描述错误、环境氛围无层次、地域特色细节失真 (如北方冬天写 “穿短袖吃冰棍”) 、物品使用场景错位 (如古代场景出现塑料水杯) 
情感与深度: 情感空洞、情感反应机械、情感强度失衡、主题表达肤浅、无独特思想内核、情感触发无铺垫、复杂情感简化、价值观输出生硬、情感转变无过渡 (如前一秒悲伤后一秒大笑) 、深层情感挖掘缺失 (仅停留在 “开心 / 难过” 表层情绪) 
叙事与创意: 叙事线索混乱、节奏失调 (过紧 / 过松) 、套路化严重、缺乏原创情节、高潮设计平淡、开篇结尾模板化、视角切换无逻辑、叙事视角不一致、叙事节奏与场景脱节 (紧张打斗场景用冗长环境描写拖慢节奏) 、创意情节虎头蛇尾 (新奇设定仅开篇出现后不再利用) 
常识与逻辑: 生活常识错误、专业知识误用、物理规律违背、时间线混乱、地理方位错误、社会规则无视、人物能力边界模糊、生活流程颠倒 (如 “先吃饭再做饭”) 、社会关系常识错误 (如将 “叔侄” 错写为 “父子”) 
结构与衔接: 章节过渡生硬、段落衔接无过渡、首尾呼应缺失、段落主旨不明确、章节标题与内容脱节、伏笔回收牵强、章节篇幅失衡 (关键章节过短 / 无关章节过长) 、段落逻辑断层 (前一段讲 A 话题后一段突然跳 B 话题无衔接) 
文化适配与地域认知: 小众文化符号滥用 (如随意使用少数民族习俗却扭曲含义) 、地域文化刻板印象 (如写南方人必 “每天吃甜粽”) 、跨文化场景适配错误 (如西方宴会写 “用筷子夹牛排”) 、历史文化常识混淆 (如将 “唐朝科举” 错写为 “宋朝殿试制度”) 
技术细节与专业场景: 专业流程描述笼统 (如写 “做实验” 却无具体操作步骤) 、专业工具功能混淆 (如将 “显微镜” 错写为 “望远镜” 用于观察细胞) 、技术场景逻辑矛盾 (如写 “电脑断网却能发送文件”) 、行业术语堆砌无意义 (如写金融场景仅反复用 “K 线”“涨停” 却无实际业务关联) 
读者互动与代入体验: 悬念勾连薄弱 (前文设的悬念后文无吸引力) 、情感共鸣点缺失 (角色遭遇无法引发读者共情) 、读者视角适配差 (如第一人称叙事突然插入第三人称上帝视角信息) 、阅读节奏失控 (如连续多章无关键信息导致读者疲劳) 



## search


为 `scrape_webpages` 函数增加单元测试, 特别是针对混合抓取策略(httpx 成功、httpx 失败后 playwright 成功、两者都失败)的场景。


`should_continue_search` 函数中的停滞检测逻辑是否可以进一步优化?例如, 除了Jaccard相似度, 是否可以引入其他更高效的文本相似度算法?


当前 `information_processor_node` 是一次性处理所有抓取到的内容, 如果内容非常多, 可能会超出LLM的上下文窗口。如何优化这个节点以处理大量内容?





