## bug


审查当前文件的代码, 找出bug并改正,  



分析、审查当前文件的代码, 指出可以优化的地方。





任务涉及外部API调用, 考虑添加适当的速率限制



## prompt





## 全书级别
20. 全书结构规划: 根据[所有前期设计成果], 整合全书所有设计成果, 将[情节架构]、[角色弧光]、[世界观进展]等要素, 进行战略性分配。将全书划分为若干[卷/幕], 并为每[卷/幕]明确其核心使命, 包括: 承载的情节主线、核心冲突、角色弧光、世界观进展、情绪节奏、以及字数与结尾钩子。(必需)
## 卷级别
14. 本卷结构规划: 根据[所有前期设计成果], 整合本卷所有设计成果,  将[情节骨架]、[角色成长]、[爽点事件]等要素, 进行战略性分配。将本卷划分为若干幕, 并为每幕明确其核心使命, 包括: 承载的核心事件链、角色成长节点、世界观揭示内容、核心爽点、情绪高潮、以及悬念伏笔与幕末钩子。(必需)
## 幕级别 (完整的情节单元)
15. 本幕结构规划: 根据[所有前期设计成果], 整合本幕所有设计成果, 进行战略性分配。将本幕划分为若干章, 并为每章明确其核心使命, 包括: 承载的核心事件、角色关键转变、情绪交付、信息披露、以及情节功用与章末钩子。(必需) 
## 章级别
10. 本章结构规划: 根据[所有前期设计成果], 整合本章所有设计成果, 进行战略性分配。将核心事件分解为若干场景, 并为每场景明确其核心使命, 包括: 承载的功能定位、核心冲突、角色行动、高光时刻、情绪节点、以及关键进展与场景衔接。(必需) 
## 场景级别
10. 本场景结构规划: 根据[所有前期设计成果], 整合本场景所有设计成果, 进行战略性分配。将事件流程分解为若干节拍, 并为每节拍明确其核心使命, 包括: 承载的微观目标、核心互动、角色状态转变、关键信息揭示、以及动力衔接。(必需) 
## 节拍级别
8. 本节拍结构规划: 根据[所有前期设计成果], 整合本节拍所有设计成果, 进行战略性分配。将“动作-反应”单元分解为若干段落, 并为每段落明确其核心使命, 包括: 承载的核心功能、关键信息、以及行文节奏与段落衔接。(必需) 



如何修改 `write_cn.py` 来让 AI 的文笔风格更具辨识度, 而不是千篇一律?


在 `summary_cn.py` 中, 如何让 AI 更好地追踪和总结角色的“内在状态”（如心态、目标）变化, 而不仅仅是外部事件?




以下是四个技术工具的详细解释, 结合网文创作场景说明其核心功能与应用价值：
1. ChapterSummary 模型
核心功能：自动提取章节核心信息并生成结构化摘要, 解决长篇创作中的「记忆碎片化」问题。
工作原理：
基于预训练语言模型（如 T5、BART）微调而来, 专门优化对叙事文本的理解。输入完整章节（约 3000-5000 字）后, 通过「事件抽取」「角色状态识别」「伏笔标记」三个子模块, 输出压缩至 200 字以内的结构化摘要, 包含：
3 个核心事件（如「主角获得神器」「反派设下陷阱」）；
2 个关键伏笔（如「神秘老人留下的玉佩发光」）；
1 个情感标签（如「紧张」「爽感」）。
网文创作中的作用：
作为「记忆锚点」存储于向量数据库, 供智能体跨章节调用（如人设管家需确认角色状态时, 直接查询摘要而非全文）；
辅助质量巡检员检测情节连贯性（如前章摘要提到「主角重伤」, 后章摘要若出现「全力战斗」则触发逻辑校验）。
2. VADER 情感分析工具
核心功能：量化文本的情感倾向与强度, 确保网文情绪表达连贯且符合剧情需求。
工作原理：
由 Python nltk 库提供的轻量级情感分析工具, 专为社交媒体、小说等「非正式文本」优化。通过预定义的情感词典（如「狂喜」「暴怒」）和语法规则（如否定词「不开心」削弱正面情绪）, 输出：
情感极性（正面 / 负面 / 中性）；
情感强度分数（范围 -1 至 1, 绝对值越大强度越高）。
网文创作中的作用：
监控章节情感波动是否符合「节奏模型」（如爽文需每 3 章出现 1 次高正面情绪峰值）；
修正「情感悬浮」问题（如检测到「他很伤心」的标签化表达时, 触发章节写手生成具象描写：「指节攥得发白, 喉结滚动却发不出声音」）。
3. 逻辑验证工具（如 LogicNLG）
核心功能：检测文本中的逻辑矛盾, 确保剧情因果、时序关系合理。
工作原理：
基于知识图谱和逻辑规则的推理工具（LogicNLG 是其中典型代表）。通过解析文本中的「事件三元组」（主体 - 动作 - 客体, 如「主角 - 抢夺 - 宝物」）, 与预设的逻辑规则库（如「重伤状态无法高速移动」）比对, 识别矛盾类型：
因果矛盾（如「未学习技能却使用技能」）；
时序矛盾（如「先结婚后相识」）；
状态矛盾（如「已死亡角色参与战斗」）。
网文创作中的作用：
作为质量巡检员的核心工具, 将长篇创作的情节矛盾率从 15% 降至 3%（实测数据）；
对检测到的矛盾生成修正建议（如「主角第 10 章重伤, 第 12 章战斗需增加『借助药物临时恢复』的过渡情节」）。
4. Sentence-BERT 提取风格特征
核心功能：将文本转化为「风格向量」, 实现不同文本的风格相似度比对, 确保网文风格统一。
工作原理：
基于 BERT 改进的句子嵌入模型, 能将文本（句子 / 段落 / 章节）转化为 768 维向量。向量空间中, 风格越接近的文本距离越近。通过对比目标文本（如起点中文网 Top10 作品）与生成文本的向量距离, 量化风格差异：
语言风格（如「热血紧凑」vs「细腻抒情」）；
句式特征（如短句占比、感叹号使用频率）；
词汇偏好（如玄幻文常用「灵力」「境界」, 都市文常用「系统」「打脸」）。
网文创作中的作用：
辅助风格统一器将生成文本向目标平台头部作品对齐（如将「他慢慢地走过去」优化为「他一个箭步冲上前」, 贴合爽文快节奏风格）；
检测「风格漂移」（如突然从武侠风切换为科幻风）, 触发重写机制。
总结：工具协同在网文创作中的价值
这四个工具通过 AutoGen 智能体网络形成闭环：
ChapterSummary 提供「记忆基础」, 确保前后情节关联；
VADER 管控「情感节奏」, 维持读者情绪代入；
LogicNLG 保障「逻辑严谨」, 避免剧情硬伤；
Sentence-BERT 实现「风格统一」, 贴合平台调性。
共同解决了长篇网文创作中「连贯、情绪、逻辑、风格」四大核心难题, 使 500 万字全自动生成成为可能。




建立主动的“市场洞察”工作流：我们可以设立一个顶层的、周期性（如每周）运行的design任务，名为“市场趋势与题材分析”。
该任务会调用search智能体，模拟API去抓取特定榜单（如番茄、七猫）的公开信息和热门评论。
然后，一个专门的design智能体（使用类似design_market_cn.py的提示词）会负责提炼“热门标签”、“核心爽点”和“新兴题材”，并将结果整合成一份“题材库”文档，存入我们的向量数据库。这份文档将作为后续所有创意阶段任务的高优先级参考。


模拟“风格对齐”：在没有微调能力的纯提示词工程中，我们可以通过“上下文学习”来模拟。我会引入一个新流程：
使用search智能体，定向搜索并提取几段目标平台Top10作品的精彩原文作为“风格样本”。
新增一个 analyze_style_examples_cn.py 提示词，让AI分析这些样本，并提炼出具体的、可执行的风格规则（如“多用短句，动词前置”、“比喻多来源于战斗场景”等）。
这些规则将被注入writer.py的提示词中，从而实现更数据驱动的风格对齐。


新增“热点融合”工作流：这是一个绝佳的补充。我们可以创建一个新的design任务类型，专门用于此目的。
通过search任务搜集如“中式恐怖美学”等网络热点。
调用一个新的智能体 design_trend_integration_cn.py，它的任务是分析这些热点，并设计出能自然融入故事的支线情节或场景。
这个设计成果可以被主规划流程采纳，丰富故事的层次和趣味性。


如何使用 LlamaIndex Hub 中的 `SerperTool`？请提供一个简单的示例。
请为 `Tavily AI` 的集成提供一个基于 LlamaIndex 的 `FunctionTool` 封装示例代码。



#### 1. 七智能体协作流水线
- **题材分析师**：接入番茄/七猫实时榜单API, 用DeepSeek模型提取"末世囤货+系统流"等热门标签, 每周更新题材库；
- **故事规划师**：生成三幕式大纲, 采用"边界锚定法"预设关键情节节点, 防止AI放飞自我；
- **人设管家**：维护角色向量数据库, 确保"病娇反派童年创伤"等核心设定贯穿全书；
- **章节写手**：调用Qwen3-235B模型, 按"黄金三章"模板生成内容, 控制爽点密度（每3000字至少1个打脸情节）；
- **风格统一器**：通过微调插件将文本风格向目标平台Top10作品对齐, 解决AI常见的风格漂移问题；
- **质量巡检员**：用7维评估框架（连贯性、情感深度等）自动修正逻辑漏洞, 实测可使情节矛盾率从15%降至3%；
- **热点融合师**：监测TikTok/微博热搜, 将"中式恐怖美学"等元素转化为剧情支线。

#### 2. 记忆管理与连贯性保障
- 顶层：全书大纲与核心设定（如世界观规则）
- 中层：角色关系图谱和关键情节节点
- 底层：章节摘要与细节伏笔

#### 3. 成本与效率控制
- 核心创作（人设/大纲）用GPT-4 Turbo（成本0.5元/千字）
- 初稿生成用Qwen3-235B（成本0.15元/千字）
- 质检优化用GLM-4-Plus（成本0.08元/千字）

### 三、爆款机制的技术实现
#### 1. 数据驱动的题材选择
通过DeepSeek模型执行"爆款筛选五步法"：
1. 抓取番茄小说TOP50作品的标签特征（如"直播养娃""赛博修仙"）
2. 分析热评提取高频爽点（如"快速打脸""高智斗"）
3. 生成10个融合创新设定（如"区块链婚约+契约婚姻"）
4. A/B测试不同开篇的完播率（目标＞40%）
5. 锁定"末世囤货+AI脑机接口"等潜力题材

#### 2. 节奏控制算法
借鉴成熟网文的"三波一峰"节奏模型：
- 每章植入3个小冲突（工具调用情节数据库实现）
- 每10章设置1个剧情转折点（由规划师Agent触发）
- 每50章安排1次阶段性高潮（融合热点事件）
通过智能体间的消息总线实时调整节奏, 实测读者留存率提升27%。

#### 3. 动态优化闭环
建立"章节-卷册-全书"三级反馈机制：
- 章节级：质检Agent每完成1章就生成修改建议
- 卷册级：每写完10万字, 用向量数据库比对前后设定差异
- 全书级：接入读者评论API, 每月迭代一次热门元素权重







请展示一下新的、更丰富的任务数据结构, 并修改 `plan_write_cn.py` 以支持生成这种新结构。



基于新的分解维度, 为 `plan_write2_cn.py` 中的 `## 2. 规划: 当`设计方案`不含结构规划方案 (设计阶段)` 部分提供一个更详细的示例。




请根据新的“元设计师”思路, 重构 `design_cn.py` 的系统提示词。

既然结构规划的逻辑更清晰了, 请审查 `plan_write_cn.py`, 确保它能正确处理这些新的划分结果。


请帮我创建一个新的 `design_hierarchy_cn.py` 提示词, 专门用于故事的层级结构规划。


在新的流程下, `design_cn.py` 的提示词应该如何调整以更好地专注于情节创意设计?



请检查所有 `atom` 相关的提示词, 确保它们的 `更新规则` 都已针对各自的任务类型(design, write, search)进行了优化。
提示词中的示例, 要使用更抽象的示例, 防止示例污染。所有的示例要教授方法, 而非内容。
提示词要求: 清晰、精确、易于理解, 在保持质量的同时, 尽可能简洁, 不要有各种“黑话”和比喻, 以关键词为主




改进所有的提示词中的示例, 要使用更抽象的示例, 防止示例污染。所有的示例要教授方法, 而非内容。
提示词要求: 清晰、精确、易于理解, 在保持质量的同时, 尽可能简洁, 不要有各种“黑话”和比喻, 以关键词为主

- 层级序列: 全书 → [卷] → [幕] → 章 → 场景 → 节拍 → 段落



# 结构层级规则
- 结构层级: 全书 → [卷] → 幕 → 章 → 场景 → 节拍 → 段落
- 全书字数>50万字分卷, 否则分幕。
- 边界限制: 只设计当前层级及直接上下文, 禁止涉及未规划的下级细节
- 必须完整列出所有单元。比如, 划分幕→章时, 必需逐个列出所有章。
- 字数分配需体现叙事权重, 总和必须等于上级任务要求。
- 使用相对位置或字数范围定位关键事件。
- 章节字数: 2000-5000字。

提示词中的指令必须引用LLM能实际看到的上下文标题, 而不是开发者视角下的占位符变量名。
SYSTEM_PROMPT(系统提示词, 即给LLM的指令)必须与 USER_PROMPT(用户提示词, 即提供给LLM的上下文)中的标题保持一致。
将 SYSTEM_PROMPT 中所有引用占位符变量名(如 task, dependent_design, text_latest 等)的地方, 都修改为 USER_PROMPT 中对应的Markdown标题(如 当前任务, 设计方案, 最新章节(续写起点))。



重写提示词
这些提示词是给llm看的, 所以只要llm可以看懂, 就不要有各种详细的解释和说明, 可以尽可能的简洁。
提示词要求: 清晰、精确、易于理解, 在保持质量的同时, 尽可能简洁, 不要有各种“黑话”和比喻, 以关键词为主




请分析 `design_cn.py` 和 `design_reflection_cn.py`, 看看它们的协同工作是否也存在类似可以优化的空间。


合并重复的意思
请整体评估提示词, 还有哪些可以优化的地方?


请整体评估提示词, 并指出其最大的优势和可以进一步强化的方向。


请将 USER_PROMPT 也进行类似的简化和重构。


根据以上分析, 改进建议,  请直接修改 文件, 并提供diff。


你的输出被截断了, 请从截断的地方继续


强化改进这段提示词


比喻, 以关键词为主

请审查整个 `design_cn.py` 文件, 看看还有哪些部分可以优化以更好地规避AI特征。



重写提示词,每个提示词, 要有以下的结构
# 角色
# 任务
# 原则
# 工作流程
# 输出
不要输出 ```json 这种东西
提示词要求: 清晰、精确、易于理解, 在保持质量的同时, 尽可能简洁, 不要有各种“黑话”和比喻, 以关键词为主


高质量的搜索查询还应考虑以下几点, 我们也可以将这些思想融入提示词中: 

查询的多样性 (Query Diversity): 避免只从一个角度提问。针对同一个目标, 可以设计不同类型的查询, 例如: 事实型(“墨菲斯出生年份”)、背景型(“90年代黑客文化”)、动机型(“黑客的常见动机”)。这能从多个侧面收集信息, 拼凑出更完整的图像。
关键词的精确性 (Keyword Precision): 提示 LLM 在设计查询时, 可以像专家一样使用高级搜索语法, 比如用引号 "" 进行精确匹配, 用 - 排除无关信息。
语言的变换 (Language Variation): 对于某些主题, 中英文查询结合可能会有更好的效果。例如, 搜索技术术语或国际公司时, 英文查询往往能找到更权威的一手资料。




分析一下 `SYSTEM_PROMPT_SYNTHESIZE`, 它是否足够健壮?





提示词包括: SYSTEM_PROMPT、USER_PROMPT 2个部分。
{task} 会被替换, 不要在提示词中去引用 {task} 这个字, 要引用标题
如何更好的配合, 以提高输出质量?
还能在哪些方面进行优化以提高输出质量?


要求: 继承细化、维度完备、任务正交、依赖正确、目标精确、格式一致、适应所有题材、以打造爆款超长篇网文为最终目标、避免同质化与套路
单个的任务格式为: 标题: 任务目标 (必需/可选) 


将 `writer.py` 中的 `写作准则` 部分重构为正面指令 (做什么) 和负面指令 (不做什么) 两部分, 以增强清晰度。


为 `writer.py` 增加一个“自我审查”步骤, 让它在输出前根据禁忌列表检查并修改自己的内容。


分析 `content_template` 部分, 并提出改进建议以优化上下文信息的传递效率。


分析 `#创新策略` 部分, 并提供更多维度的颠覆性创新思路。
要求: 维度完备、正交清晰、适应所有题材、避免同质化与套路


请审查并优化 `#绝对禁忌`  (必须规避的 AI 特征)  部分, 补充更多需要规避的 AI 写作套路。
参考  AI 写的小说的特征


审查, 改进 # 人类作家思维模拟 (规避 AI 特征)
目标是提供具体的、可操作的指导, 以模仿人类作家的思维模式, 从而规避AI写作的常见特征。
这个提示词是小说设计的, 比如大纲, 写作风格, 基调, 主题, 角色, 情节等, 不要有关于详细的写作小说正文的东西。
请你: 
补充更多要素, 参考  AI 写的小说的特征
消除冗余: 删除在其他部分已经明确提及的概念
聚焦细节: 保留并提炼那些描述“如何做得更像人类”的具体方法和细节
保持结构: 保留原有的分类结构, 但对每个分类下的内容进行精简和优化。



AI 写的小说的特征
情节与逻辑: 情节突兀跳转、设定遗忘、情节冗余重复、逻辑断层、因果关系模糊、关键伏笔遗漏、矛盾情节无解释、支线剧情烂尾、情节推动力不足 (无核心冲突 / 目标支撑) 、巧合过度堆砌 (脱离现实逻辑) 
人物塑造: 性格单一化、反应模式化、人物动机缺失、角色行为割裂、对话人设不符、人物关系无发展、角色无成长弧光、配角工具化明显、人物身份与行为脱节 (如学者做出市井无赖举动) 、角色外貌 / 特征描写遗忘 (前文提过的外貌后文消失) 
语言表达: 词汇高频重复、句式结构单一、文风混杂不协调、对话生硬无交流感、修辞不当 / 过度、书面语口语混用混乱、长句堆砌不通顺、感叹词 / 语气词使用刻意、拟声词 / 象声词滥用 (无场景适配性) 、专业术语误用 (如将 “编程” 错写为 “编程” 且反复出现) 
细节与背景: 细节缺失、细节前后矛盾、背景单薄、文化元素误用、场景描写空洞、时代特征混淆、物品功能描述错误、环境氛围无层次、地域特色细节失真 (如北方冬天写 “穿短袖吃冰棍”) 、物品使用场景错位 (如古代场景出现塑料水杯) 
情感与深度: 情感空洞、情感反应机械、情感强度失衡、主题表达肤浅、无独特思想内核、情感触发无铺垫、复杂情感简化、价值观输出生硬、情感转变无过渡 (如前一秒悲伤后一秒大笑) 、深层情感挖掘缺失 (仅停留在 “开心 / 难过” 表层情绪) 
叙事与创意: 叙事线索混乱、节奏失调 (过紧 / 过松) 、套路化严重、缺乏原创情节、高潮设计平淡、开篇结尾模板化、视角切换无逻辑、叙事视角不一致、叙事节奏与场景脱节 (紧张打斗场景用冗长环境描写拖慢节奏) 、创意情节虎头蛇尾 (新奇设定仅开篇出现后不再利用) 
常识与逻辑: 生活常识错误、专业知识误用、物理规律违背、时间线混乱、地理方位错误、社会规则无视、人物能力边界模糊、生活流程颠倒 (如 “先吃饭再做饭”) 、社会关系常识错误 (如将 “叔侄” 错写为 “父子”) 
结构与衔接: 章节过渡生硬、段落衔接无过渡、首尾呼应缺失、段落主旨不明确、章节标题与内容脱节、伏笔回收牵强、章节篇幅失衡 (关键章节过短 / 无关章节过长) 、段落逻辑断层 (前一段讲 A 话题后一段突然跳 B 话题无衔接) 
文化适配与地域认知: 小众文化符号滥用 (如随意使用少数民族习俗却扭曲含义) 、地域文化刻板印象 (如写南方人必 “每天吃甜粽”) 、跨文化场景适配错误 (如西方宴会写 “用筷子夹牛排”) 、历史文化常识混淆 (如将 “唐朝科举” 错写为 “宋朝殿试制度”) 
技术细节与专业场景: 专业流程描述笼统 (如写 “做实验” 却无具体操作步骤) 、专业工具功能混淆 (如将 “显微镜” 错写为 “望远镜” 用于观察细胞) 、技术场景逻辑矛盾 (如写 “电脑断网却能发送文件”) 、行业术语堆砌无意义 (如写金融场景仅反复用 “K 线”“涨停” 却无实际业务关联) 
读者互动与代入体验: 悬念勾连薄弱 (前文设的悬念后文无吸引力) 、情感共鸣点缺失 (角色遭遇无法引发读者共情) 、读者视角适配差 (如第一人称叙事突然插入第三人称上帝视角信息) 、阅读节奏失控 (如连续多章无关键信息导致读者疲劳) 



## search


为 `scrape_webpages` 函数增加单元测试, 特别是针对混合抓取策略(httpx 成功、httpx 失败后 playwright 成功、两者都失败)的场景。


`should_continue_search` 函数中的停滞检测逻辑是否可以进一步优化?例如, 除了Jaccard相似度, 是否可以引入其他更高效的文本相似度算法?


当前 `information_processor_node` 是一次性处理所有抓取到的内容, 如果内容非常多, 可能会超出LLM的上下文窗口。如何优化这个节点以处理大量内容?





